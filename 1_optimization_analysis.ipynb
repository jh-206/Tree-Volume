{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96baf42-a11e-424c-9df8-233b68690efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d7814-431f-4afb-8cf0-dc9a83b66563",
   "metadata": {},
   "source": [
    "# Modeling Trees as Truncated Cones using Convex Optmization\n",
    "\n",
    "The purpose of this notebook is to fit the truncated cone model introduced in the previous notebook using convex optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b167f2b-50ad-4710-a8ed-d415b153a5ec",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "It is a common practice in forestry to estimate tree volume from measurements of tree diameter (DBH) and height. This topic is of key interest to researchers and industry. In forestry, it is economically valuable to have a reliable estimate of usable timber in a stand of trees that might take years to mature. In researching climate change, it is valuable to know how much carbon trees can sequester, which is related to the volume of the tree.  \n",
    "\n",
    "The purpose of this notebook is to present a model of tree volume based on the geometry of a truncated cone. For more on the standard regression approaches to the problem, see the previous notebook. The data used will be the Trees dataset built-in to the R programming language.\n",
    "\n",
    "All code can be found on: https://github.com/jh-206/Tree-Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5d62c-b9e1-4aa0-a5ce-e0f0f67f4c1f",
   "metadata": {},
   "source": [
    "<img src=\"images/tcone.png\" alt=\"alt text\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c88d2a-eb62-4131-9d34-701e55463577",
   "metadata": {},
   "source": [
    "## Model Formulation\n",
    "\n",
    "The volume observations in the data is sometimes referred to as \"merchantable volume\". It is found by removing branches from trunk of the tree, and the final volume value is directly related to the amount of usable timber in the trunk of the tree. For these reasons, the trunk looks like a big truncated cone. A truncated cone is defined by a lower radius and an upper radius.\n",
    "\n",
    "$$\n",
    "V = \\frac{1}{3}\\pi (r_1^2+r_1r_2+r_2^2)h\n",
    "$$\n",
    "\n",
    "Where $V$ is the observed volume of the tree and $h$ is the observed height. Then, $r_1$ and $r_2$ are the radii of the base and top of the cone, respectively.\n",
    "\n",
    "We will consider the upper radius to be a fraction of the lower radius. So, we introduce a parameter $\\alpha$ where $r_2 = \\alpha r_1, \\text{ for }\\alpha \\in (0,1)$. We will use a grid search to find an alpha that minimizes the fitted sum of squares. Let the lower tree radius be $r$ and the upper be $r_2$. Since $r_2 = \\alpha r$, using $\\hat V_i$ to represent the estimated volume of tree $i$, we can write the volume as:\n",
    "\n",
    "$$\n",
    "\\hat V_i = \\frac{1}{3}\\cdot \\pi h_i r_i^2(1+\\alpha+\\alpha^2), \\;\\alpha\\in(0,1), i=1, ..., N\n",
    "$$\n",
    "\n",
    "Where $V_i$ is the observed volume of the $i$th tree, where $i$ equals $1, ..., N$ where $N$ is the total number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38042a7-2e5d-45e8-a4e0-9d73e1e11efc",
   "metadata": {},
   "source": [
    "Formulating this as an optimization problem, we seek to minimize the sum of squares of the residuals. The observed values are radius ($r_i$), height ($h_i$), and volume ($V_i$), for $i=1, ..., N$. Here, $N$ is the total number of observations (31 for the trees dataset).\n",
    "\n",
    "We want to minimize the sum of squared residuals, so our loss function is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min &\\sum_{i=1}^N \\left(\\pi\\frac{h_i}{3} r_i^2(1+\\alpha+\\alpha^2) - V_i\\right)^2\\\\\n",
    "    \\text{s.t. }&\\alpha\\in[0,1]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a764f-8065-41a7-856f-c73086c67857",
   "metadata": {},
   "source": [
    "To represent this in matrix notation, Let $V=\\begin{pmatrix}V_1 \\\\ V_2 \\\\ \\vdots \\\\ V_N\\end{pmatrix}$ and $hr^2 = \\begin{pmatrix}h_1r_1^2 \\\\ h_2r_2^2 \\\\ \\vdots \\\\ h_Nr_N^2\\end{pmatrix}$\n",
    "\n",
    "Putting this all together, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min &\\|\\pi\\frac{h}{3} r^2(1+\\alpha+\\alpha^2)-V\\|_2^2 \\\\\n",
    "    \\text{s.t. }&0\\leq\\alpha\\leq 1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where solutions are scalar values $\\alpha\\in \\mathbb R$, with $\\alpha\\in [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c327eed-35cd-40e5-ac5e-bdc0ec79031f",
   "metadata": {},
   "source": [
    "### Code-Friendly Formulation\n",
    "\n",
    "We seek to write the minimation problem in the form $\\min (Ax-b)$ to play nice with `cvxpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f48213-45bd-4289-a411-957ee86d5b1d",
   "metadata": {},
   "source": [
    "First, since $1+\\alpha+\\alpha^2$ is one-to-one over $[0,1]$, we can define $a=1+\\alpha+\\alpha^2$ and then use the optimal value of $a$ to uniquely solve for $\\alpha$. If $\\alpha\\in[0,1]$, we know that $1+\\alpha+\\alpha^2$ is in the interval $[1, 3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d971e14-8e2b-4421-9641-57b68b8090c8",
   "metadata": {},
   "source": [
    "So we convert the constraint from the previous problem to $a\\in[1,3]$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min &\\|\\pi\\frac{h}{3} r^2 a - V\\|_2^2 \\\\\n",
    "    \\text{s.t. }&1\\leq a \\leq 3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b867f5-8dc1-40a3-b98e-23f2f1110c3c",
   "metadata": {},
   "source": [
    "## Read Data and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79872e-e318-451c-a2b3-a821cbef3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pd.read_csv(\"trees.csv\")\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a0436-227a-48aa-9306-5b3c267b94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (trees.d/2).to_numpy() # DBH Divided by height\n",
    "h = trees.h.to_numpy()\n",
    "V = trees.v.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a758c6-f2bc-4227-9ee1-044300badb8d",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c07fe-92e7-4d8f-af3f-b79a7b51ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6596) # NLP CU Denver Course number used as seed\n",
    "\n",
    "a = cp.Variable(1, pos=True) # alpha parameter, target of interest\n",
    "objective=cp.sum_squares(h/3*np.pi*r**2 * a - V) # Objective Function\n",
    "constraints = [a>= 1, a<=3]\n",
    "prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30677a82-8400-4f87-9828-78125deacd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369ad23-2336-4872-b03c-b8695958e9a5",
   "metadata": {},
   "source": [
    "### Final Optimization Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7399e-1c9c-459e-bae1-969215c6d7c8",
   "metadata": {},
   "source": [
    "Using the optmized value of $a$, we solve for the unique value of $\\alpha$ by first setting up a quadratic root problem:\n",
    "\n",
    "$$\n",
    "1+\\alpha+\\alpha^2 = a\n",
    "$$\n",
    "\n",
    "Then, we use the QUADRATIC FORMULA(!!) and ignore the negative root that would correspond to an $\\alpha$ outside of $[0,1]$.\n",
    "\n",
    "$$\n",
    "\\frac{-1\\pm\\sqrt{1-4*1*(1-a)}}{2}\n",
    "$$\n",
    "\n",
    "We calculate with code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfaee12-6e91-459b-bd12-1329046a50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((-1-np.sqrt(1-4*(1-a.value)))/2)\n",
    "print((-1+np.sqrt(1-4*(1-a.value)))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b95a77-6050-46eb-ac63-85dd14d81898",
   "metadata": {},
   "source": [
    "Therefore, the final estimate of $\\alpha$ is $0.13995219$, or roughly $0.14$. Connecting this back to the physical problem, that means that if we represent a tree trunk as a truncated cone with a known lower radius $r$, the volume of the tree will be approximated best by using an upper radius of $0.14*r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa05a7-5685-4a9e-aacc-4e980038d759",
   "metadata": {},
   "source": [
    "## Error and Uncertainty Analysis\n",
    "\n",
    "To estimate the error associated with the model, and additionally to produce a confidence interval for the alpha parameter, we perform the following cross validation procedure: for 1,000 replications, split the data into an 80/20 percentage split, find the optimal parameter for the training set, and calculate the error when using that optimal parameter to predict new data. (Note: this is a form of cross-validation sometimes called Monte Carlo CV. There are more elegant coding approaches to this, but I think this is good for clearly demonstrating the technique.)\n",
    "\n",
    "Koirala etal 2017 arrived at the following model specification after testing various formulations:\n",
    "$$\n",
    "V = \\beta_0+\\beta_1\\cdot d + \\beta_2\\cdot d^2\\cdot h \n",
    "$$\n",
    "\n",
    "The model therefore has 3 uncertain parameters, and a 4th if you add estimating the random error variance that is typical in linear regression models. This model will be compared to the truncated cone model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fea14-c0ca-4ad4-bb29-ccdcb110a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nreps = 1000\n",
    "alphas = np.zeros(nreps) # initialize array of parameters\n",
    "rmses = np.zeros(nreps) # initialize array of RMSE errors\n",
    "rmses_lm = np.zeros(nreps) # initialize array of RMSE errors\n",
    "np.random.seed(123)\n",
    "\n",
    "for i in range(0, nreps):\n",
    "    # print(\"~\"*40)\n",
    "    # print(f\"Iteration {i}\")\n",
    "    # print(f\"Seed: {}\")\n",
    "    # Split Data\n",
    "    np.random.seed()\n",
    "    inds = np.random.choice([0, 1], size=len(trees), p=[0.8, 0.2]) # generate labels for train/test\n",
    "    train = trees[inds == 0]\n",
    "    test = trees[inds == 1]\n",
    "    # Find optimal param\n",
    "    r = (train.d/2).to_numpy() # DBH Divided by height\n",
    "    h = train.h.to_numpy()\n",
    "    V = train.v.to_numpy()\n",
    "    a = cp.Variable(1, pos=True) # alpha parameter, target of interest\n",
    "    np.random.seed(6596) # NLP CU Denver Course number used as seed\n",
    "    objective=cp.sum_squares(h/3*np.pi*r**2 * a - V) # Objective Function\n",
    "    constraints = [a>= 1, a<=3]\n",
    "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    temp = prob.solve()\n",
    "    alphas[i] = (-1+np.sqrt(1-4*(1-a.value[0])))/2\n",
    "\n",
    "    # LM Model\n",
    "    X = train[[\"d\", \"h\"]].copy()\n",
    "    X=X.assign(d2h = X['d']**2 * X['h'])\n",
    "    X[\"const\"] = np.ones(X.shape[0])\n",
    "    lm = sm.OLS(train.v, X).fit()\n",
    "    \n",
    "    X_test = test[[\"d\", \"h\"]].copy()\n",
    "    X_test=X_test.assign(d2h = X_test['d']**2 * X_test['h'])\n",
    "    X_test[\"const\"] = np.ones(X_test.shape[0])\n",
    "    \n",
    "    # Predict and calculate error\n",
    "    preds = test['h']/3*np.pi*(test['d']/2)**2 * a.value[0]\n",
    "    rmses[i] = np.sqrt(np.sum((preds-test.v)**2))\n",
    "\n",
    "    preds2 = lm.predict(X_test)\n",
    "    rmses_lm[i] = np.sqrt(np.sum((preds2-test.v)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92c9cf-83d8-4cde-9540-d5f8281797b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Alpha: {alphas.mean()}\")\n",
    "print(f\"95% Empirical Interval: {np.percentile(alphas, 2.5), np.percentile(alphas, 97.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e877d3-f807-4e9b-bf5d-bb1a265fe665",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alphas)\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(alphas.mean(), color='r', linestyle='--', linewidth=2)\n",
    "plt.text(alphas.mean(), plt.ylim()[1]*.7, r'Mean $\\alpha$', rotation=90, color='r', verticalalignment='bottom', horizontalalignment='right')\n",
    "\n",
    "plt.axvline(np.percentile(alphas, 2.5), color='r', linestyle='--', linewidth=2, alpha=.6)\n",
    "plt.text(np.percentile(alphas, 2.5), plt.ylim()[1]*.7, r'2.5 percentile', rotation=90, alpha=.6, color='r', verticalalignment='bottom', horizontalalignment='right')\n",
    "\n",
    "plt.axvline(np.percentile(alphas, 97.5), color='r', linestyle='--', linewidth=2, alpha=.6)\n",
    "plt.text(np.percentile(alphas, 97.5), plt.ylim()[1]*.7, r'97.5 percentile', rotation=90, color='r', alpha=.6, verticalalignment='bottom', horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada745d-4ac5-4f78-af5d-4424dcce12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Model' : [\"T. Cone\", \"Lin Reg\"],\n",
    "    'Mean Test RMSE' : np.round([rmses.mean(), rmses_lm.mean()], 3),\n",
    "    'Low (2.5%)' : np.round([np.percentile(rmses, 2.5), np.percentile(rmses_lm, 2.5)], 3),\n",
    "    'High (97.5%)' : np.round([np.percentile(rmses, 97.5), np.percentile(rmses_lm, 97.5)], 3)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373ea05-4972-4c21-b593-45827ded9aa6",
   "metadata": {},
   "source": [
    "## Adding Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1583fe5-de64-46b8-8d77-a7e02dc2c5b9",
   "metadata": {},
   "source": [
    "In the absence of data from multiple species, I will generate random species labels for my existing dataset and use that for modeling. In theory, there should be zero effect from species, since the species labels are generated randomly and have no relation to the outcome variable of volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cccc33-007b-4e50-9278-05603941040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate species\n",
    "np.random.seed(6596) # NLP CU Denver Course number used as seed\n",
    "trees['species'] = np.random.randint(2, size=len(trees))\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da7f07-37c2-4c7f-85db-7a9822daa136",
   "metadata": {},
   "source": [
    "We introduce a simple additive effect from species, denoted $\\beta$. So we modify the original volume formula by adding a parameter by adding $\\beta$ times the species label. Suppose $S_i$ is the species of observation $i$. Then the volume formula of the truncated cone with an additive constant effect from species, we get:\n",
    "\n",
    "$$\n",
    "V_i = \\frac{1}{3}\\cdot \\pi h_i r_i^2(1+\\alpha+\\alpha^2)+\\beta S_i, \\;\\alpha\\in(0,1), i = 1, ..., N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d862ced-b282-4460-94f4-be34353f13e8",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    \\min &\\|\\frac{h}{3}\\pi r^2 a + \\beta S - V\\|_2^2 \\\\\n",
    "    \\text{s.t. }&1\\leq a \\leq 3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c37cf-ef42-4d45-8489-5587d32279a5",
   "metadata": {},
   "source": [
    "We solve this problem with `cvxpy`. We again transform $a$ back into the parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cf32c-201b-4466-8254-f26bf17e97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (trees.d/2).to_numpy() # DBH Divided by height\n",
    "h = trees.h.to_numpy()\n",
    "V = trees.v.to_numpy()\n",
    "S = trees.species.to_numpy()\n",
    "a = cp.Variable(1, pos=True) # alpha parameter, target of interest\n",
    "b = cp.Variable(1) # beta parameter, additivie species effect\n",
    "np.random.seed(6596) # NLP CU Denver Course number used as seed\n",
    "\n",
    "objective=cp.sum_squares(h/3*np.pi*r**2 * a+b*S - V) # Objective Function\n",
    "constraints = [a>= 1, a<=3]\n",
    "prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db474ec7-ef50-4075-bde7-7d7d0f31a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Alpha Value: {(-1+np.sqrt(1-4*(1-a.value)))/2}\")\n",
    "print(f\"Beta value: {b.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d0a81-320a-447b-8b9d-eb0a46790e98",
   "metadata": {},
   "source": [
    "We expected the $\\beta$ parameter value to be zero, since there is no actual effect from species. But this effect is small relative to the average observed volume of a tree and the average fitted volume from the truncated cone model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4192e0-0078-4b51-8f8c-e5b5d57505b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Observed Volume: {np.round(trees.v.mean(), 3)}\")\n",
    "print(f\"Optimized Species Effect: {np.round(b.value[0], 3)}\")\n",
    "print(f\"Species Effect, Percent of Average Volume: {np.round(100*b.value[0]/trees.v.mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc8e49-7d12-40dd-8ba5-6f518f23e0c9",
   "metadata": {},
   "source": [
    "So even though the parameter $\\beta$ is nonzero, the optmized value represents less than 1% of the average tree volume.\n",
    "\n",
    "As a further check, we repeat the randomly species labeling 1,000 times and examine the resulting $\\beta$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20816c51-1367-4f8e-8556-a75c934542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6596) # NLP CU Denver Course number used as seed\n",
    "nreps = 1000\n",
    "betas = np.zeros(nreps) # initialize vector of beta valuees\n",
    "for i in range(0, nreps):\n",
    "    trees['species'] = np.random.randint(2, size=len(trees)) # randomly assign species labels\n",
    "    S = trees.species.to_numpy() # re-extract species label to array\n",
    "    a = cp.Variable(1, pos=True) # re-declare beta parameter\n",
    "    b = cp.Variable(1) # re-declare beta parameter\n",
    "    objective=cp.sum_squares(h/3*np.pi*r**2 * a+b*S - V) # Objective Function\n",
    "    constraints = [a>= 1, a<=3]\n",
    "    # Solve problem\n",
    "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    prob.solve()\n",
    "    # Extract beta value for this iteration\n",
    "    betas[i]=b.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48240a-7f8a-4ae8-8898-66ceddab6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Beta Value: {np.round(betas.mean(), 3)}\")\n",
    "print(f\"Average Beta Value as Percent of Mean Volume: {np.round(100*betas.mean() / trees.v.mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ac095-552a-45ef-ba3f-753a34ffcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(betas)\n",
    "plt.title(\"Distribution of Beta Parameter\")\n",
    "plt.xlabel(\"Beta\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6d519-9bd7-4092-81a4-185b7c12d9d4",
   "metadata": {},
   "source": [
    "The resulting distribution of $\\beta$ values is centered on zero and has a roughly normal distribution. This matches what we would expect theoretically based on the Central Limit Theorem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28456995-8907-4c75-8909-e8618f5feecc",
   "metadata": {},
   "source": [
    "## Discussion and Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d985d-fe7c-4de7-8161-31dfd6b233f4",
   "metadata": {},
   "source": [
    "This report shows how to solve a geometrically formulated estimate of tree volume, given the typical forestry field measurements of tree diameter and height. This formulation of a volume model has advantages over standard statistical approaches in a few ways. First, the basic truncated cone model has only one uncertain parameter, while typical linear regression methods would use up degrees of freedom estimating typically 4 or more paramters (one each for height, diameter, random error, and a constant mean effect). Second, the geometrically inspired model gives potentially more physical insight. The truncated cone formulation can be used to get a natural estimate of surface area of the tree, for example. The surface area of a tree might be a useful value to estimate, if for instance the logs were to be painted or wrapped in some material and you wanted an estimate of how much you would need. A standard linear regression model would provide zero estimate of surface area. \n",
    "\n",
    "This report shows how an effect from species could be added, given more data for different tree species. Numerical experimentation above shows that if species labels are random, and thus have no relationship with volume, the resulting estimates of the additive effect from species vary about the expected value of zero with a roughly normal distribution.\n",
    "\n",
    "This project could be developed and extended to a scientific contribution to forestry modeling. First, we could collect more data, preferrably the data used to develop models published in the academic literature and cited in the references of this report. Next, we could compare the truncated cone volume model to the various other models in the literature. Preliminary investigation shows that the truncated cone volume model fits this data of 31 cherry trees more accurately and with less uncertainty of relevant parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e6950-6576-43a0-936f-c74d5179773a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Koirala, Anil & Kizha, Anil Raj & Baral, Srijana. (2017). Modeling Height-Diameter Relationship and Volume of Teak (Tectona grandis L. F.) in Central Lowlands of Nepal. Journal of Tropical Forestry and Environment. 07. 28-42. 10.31357/jtfe.v7i1.3020. \n",
    "\n",
    "Birteeb, Peter & Ajit, & Varghese, Cini & Jaggi, Seema. (2020). Development and comparative diagnosis of conventional (linear/nonlinear) and artificial intelligence techniques-based predictive models for estimating timber volume of Tectona grandis. International Journal of Ecology and Environmental Sciences. 2. 1-11. \n",
    "\n",
    "https://stats.libretexts.org/Bookshelves/Probability_Theory/Book%3A_Introductory_Probability_(Grinstead_and_Snell)/09%3A_Central_Limit_Theorem/9.01%3A_Central_Limit_Theorem_for_Bernoulli_Trials#:~:text=Central%20Limit%20Theorem%20for,%CF%95(x)dx%20.&text=This%20theorem%20can%20be%20proved,k)%20given%20in%20Theorem%209.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
